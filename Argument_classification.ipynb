{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading vocabulary file argument_classification_ukp/vocab.txt\n",
      ":: Sentences longer than max_sequence_length: 0\n",
      ":: Num sentences: 1956\n",
      "loading archive file argument_classification_ukp/\n",
      "Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Argumentative': {'precision': 0.5833333333333334, 'recall': 0.006097560975609756, 'f1-score': 0.01206896551724138, 'support': 1148}, 'Non_Argumentative': {'precision': 0.4130658436213992, 'recall': 0.9938118811881188, 'f1-score': 0.5835755813953489, 'support': 808}, 'accuracy': 0.41411042944785276, 'macro avg': {'precision': 0.4981995884773663, 'recall': 0.4999547210818643, 'f1-score': 0.29782227345629514, 'support': 1956}, 'weighted avg': {'precision': 0.5129978876854587, 'recall': 0.41411042944785276, 'f1-score': 0.24815145305789113, 'support': 1956}}\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from train import InputExample, convert_examples_to_features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "### Argument Classification Using fine tuned BERT Model\n",
    "\n",
    "train_tweets = pd.read_pickle('/Users/william/Desktop/Thesis_code/train_tweets.pkl')\n",
    "test_tweets = pd.read_pickle('/Users/william/Desktop/Thesis_code/test_tweets.pkl')\n",
    "\n",
    "\n",
    "def convert_to_input_examples(data):\n",
    "    input_examples = []\n",
    "    target = data['Target'].iloc[0]\n",
    "    data = data['Processed_Tweet_sw'].tolist()\n",
    "    for tweet in data:\n",
    "        input_examples.append(InputExample(text_a=target,text_b=tweet,label=\"NoArgument\"))\n",
    "    return input_examples\n",
    "\n",
    "input_examples = convert_to_input_examples(test_tweets)\n",
    "\n",
    "\n",
    "\n",
    "num_labels = 3\n",
    "model_path = 'argument_classification_ukp/'\n",
    "label_list = [\"NoArgument\", \"Argument_against\", \"Argument_for\"]\n",
    "max_seq_length = 64\n",
    "eval_batch_size = 8\n",
    "\n",
    "#Input examples. The model 'bert_output/ukp/bert-base-topic-sentence/all_topics/' expects text_a to be the topic\n",
    "#and text_b to be the sentence. label is an optional value, only used when we print the output in this script.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path, do_lower_case=True)\n",
    "eval_features = convert_examples_to_features(input_examples, label_list, max_seq_length, tokenizer)\n",
    "\n",
    "all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "\n",
    "eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids)\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predicted_labels = []\n",
    "with torch.no_grad():\n",
    "    for input_ids, input_mask, segment_ids in eval_dataloader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "\n",
    "\n",
    "        logits = model(input_ids, segment_ids, input_mask)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "\n",
    "        for prediction in np.argmax(logits, axis=1):\n",
    "            predicted_labels.append(label_list[prediction])\n",
    "\n",
    "\n",
    "\n",
    "test_tweets['Predicted_Label'] = predicted_labels\n",
    "\n",
    "test_tweets['Predicted_Label'] = test_tweets['Predicted_Label'].replace(['Argument_against','Argument_for'],'Argumentative')\n",
    "test_tweets['Predicted_Label'] = test_tweets['Predicted_Label'].replace(['NoArgument'],'Non_Argumentative')\n",
    "\n",
    "\n",
    "\n",
    "report = classification_report(test_tweets['Opinion Towards'],test_tweets['Predicted_Label'],output_dict=True)\n",
    "\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flair_nlp",
   "language": "python",
   "name": "flair_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
